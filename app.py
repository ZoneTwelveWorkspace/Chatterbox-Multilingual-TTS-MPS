import random

import gradio as gr
import numpy as np
import torch

from src.chatterbox.enhanced_tts import (
    EnhancedTTS,
    GenerationResult,
    TTSGenerationConfig,
    create_enhanced_tts,
    generate_speech,
)
from src.chatterbox.mtl_tts import SUPPORTED_LANGUAGES, ChatterboxMultilingualTTS
from src.chatterbox.text_chunker import chunk_text_with_info, smart_chunk_text

# Device detection with MPS support for Apple Silicon Macs
DEVICE = (
    "mps"
    if torch.backends.mps.is_available()
    else ("cuda" if torch.cuda.is_available() else "cpu")
)
print(f"üöÄ Running on device: {DEVICE}")

# --- Global Model Initialization ---
MODEL = None
ENHANCED_TTS = None  # Enhanced TTS with text chunking support

LANGUAGE_CONFIG = {
    "ar": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ar_f/ar_prompts2.flac",
        "text": "ŸÅŸä ÿßŸÑÿ¥Ÿáÿ± ÿßŸÑŸÖÿßÿ∂Ÿäÿå ŸàÿµŸÑŸÜÿß ÿ•ŸÑŸâ ŸÖÿπŸÑŸÖ ÿ¨ÿØŸäÿØ ÿ®ŸÖŸÑŸäÿßÿ±ŸäŸÜ ŸÖŸÜ ÿßŸÑŸÖÿ¥ÿßŸáÿØÿßÿ™ ÿπŸÑŸâ ŸÇŸÜÿßÿ™ŸÜÿß ÿπŸÑŸâ ŸäŸàÿ™ŸäŸàÿ®.",
    },
    "da": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/da_m1.flac",
        "text": "Sidste m√•ned n√•ede vi en ny milep√¶l med to milliarder visninger p√• vores YouTube-kanal.",
    },
    "de": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/de_f1.flac",
        "text": "Letzten Monat haben wir einen neuen Meilenstein erreicht: zwei Milliarden Aufrufe auf unserem YouTube-Kanal.",
    },
    "el": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/el_m.flac",
        "text": "Œ§ŒøŒΩ œÄŒµœÅŒ±œÉŒºŒ≠ŒΩŒø ŒºŒÆŒΩŒ±, œÜœÑŒ¨œÉŒ±ŒºŒµ œÉŒµ Œ≠ŒΩŒ± ŒΩŒ≠Œø ŒøœÅœåœÉŒ∑ŒºŒø ŒºŒµ Œ¥œçŒø Œ¥ŒπœÉŒµŒ∫Œ±œÑŒøŒºŒºœçœÅŒπŒ± œÄœÅŒøŒ≤ŒøŒªŒ≠œÇ œÉœÑŒø Œ∫Œ±ŒΩŒ¨ŒªŒπ ŒºŒ±œÇ œÉœÑŒø YouTube.",
    },
    "en": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/en_f1.flac",
        "text": "Last month, we reached a new milestone with two billion views on our YouTube channel.",
    },
    "es": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/es_f1.flac",
        "text": "El mes pasado alcanzamos un nuevo hito: dos mil millones de visualizaciones en nuestro canal de YouTube.",
    },
    "fi": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/fi_m.flac",
        "text": "Viime kuussa saavutimme uuden virstanpylv√§√§n kahden miljardin katselukerran kanssa YouTube-kanavallamme.",
    },
    "fr": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/fr_f1.flac",
        "text": "Le mois dernier, nous avons atteint un nouveau jalon avec deux milliards de vues sur notre cha√Æne YouTube.",
    },
    "he": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/he_m1.flac",
        "text": "◊ë◊ó◊ï◊ì◊© ◊©◊¢◊ë◊® ◊î◊í◊¢◊†◊ï ◊ú◊ê◊ë◊ü ◊ì◊®◊ö ◊ó◊ì◊©◊î ◊¢◊ù ◊©◊†◊ô ◊û◊ô◊ú◊ô◊ê◊®◊ì ◊¶◊§◊ô◊ï◊™ ◊ë◊¢◊®◊ï◊• ◊î◊ô◊ï◊ò◊ô◊ï◊ë ◊©◊ú◊†◊ï.",
    },
    "hi": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/hi_f1.flac",
        "text": "‡§™‡§ø‡§õ‡§≤‡•á ‡§Æ‡§π‡•Ä‡§®‡•á ‡§π‡§Æ‡§®‡•á ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§Æ‡•Ä‡§≤ ‡§ï‡§æ ‡§™‡§§‡•ç‡§•‡§∞ ‡§õ‡•Å‡§Ü: ‡§π‡§Æ‡§æ‡§∞‡•á YouTube ‡§ö‡•à‡§®‡§≤ ‡§™‡§∞ ‡§¶‡•ã ‡§Ö‡§∞‡§¨ ‡§µ‡•ç‡§Ø‡•Ç‡§ú‡§º‡•§",
    },
    "it": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/it_m1.flac",
        "text": "Il mese scorso abbiamo raggiunto un nuovo traguardo: due miliardi di visualizzazioni sul nostro canale YouTube.",
    },
    "ja": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ja/ja_prompts1.flac",
        "text": "ÂÖàÊúà„ÄÅÁßÅ„Åü„Å°„ÅÆYouTube„ÉÅ„É£„É≥„Éç„É´„Åß‰∫åÂçÅÂÑÑÂõû„ÅÆÂÜçÁîüÂõûÊï∞„Å®„ÅÑ„ÅÜÊñ∞„Åü„Å™„Éû„Ç§„É´„Çπ„Éà„Éº„É≥„Å´Âà∞ÈÅî„Åó„Åæ„Åó„Åü„ÄÇ",
    },
    "ko": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ko_f.flac",
        "text": "ÏßÄÎÇúÎã¨ Ïö∞Î¶¨Îäî Ïú†ÌäúÎ∏å Ï±ÑÎÑêÏóêÏÑú Ïù¥Ïã≠Ïñµ Ï°∞ÌöåÏàòÎùºÎäî ÏÉàÎ°úÏö¥ Ïù¥Ï†ïÌëúÏóê ÎèÑÎã¨ÌñàÏäµÎãàÎã§.",
    },
    "ms": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ms_f.flac",
        "text": "Bulan lepas, kami mencapai pencapaian baru dengan dua bilion tontonan di saluran YouTube kami.",
    },
    "nl": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/nl_m.flac",
        "text": "Vorige maand bereikten we een nieuwe mijlpaal met twee miljard weergaven op ons YouTube-kanaal.",
    },
    "no": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/no_f1.flac",
        "text": "Forrige m√•ned n√•dde vi en ny milep√¶l med to milliarder visninger p√• YouTube-kanalen v√•r.",
    },
    "pl": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/pl_m.flac",
        "text": "W zesz≈Çym miesiƒÖcu osiƒÖgnƒôli≈õmy nowy kamie≈Ñ milowy z dwoma miliardami wy≈õwietle≈Ñ na naszym kanale YouTube.",
    },
    "pt": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/pt_m1.flac",
        "text": "No m√™s passado, alcan√ß√°mos um novo marco: dois mil milh√µes de visualiza√ß√µes no nosso canal do YouTube.",
    },
    "ru": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/ru_m.flac",
        "text": "–í –ø—Ä–æ—à–ª–æ–º –º–µ—Å—è—Ü–µ –º—ã –¥–æ—Å—Ç–∏–≥–ª–∏ –Ω–æ–≤–æ–≥–æ —Ä—É–±–µ–∂–∞: –¥–≤–∞ –º–∏–ª–ª–∏–∞—Ä–¥–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –Ω–∞ –Ω–∞—à–µ–º YouTube-–∫–∞–Ω–∞–ª–µ.",
    },
    "sv": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/sv_f.flac",
        "text": "F√∂rra m√•naden n√•dde vi en ny milstolpe med tv√• miljarder visningar p√• v√•r YouTube-kanal.",
    },
    "sw": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/sw_m.flac",
        "text": "Mwezi uliopita, tulifika hatua mpya ya maoni ya bilioni mbili kweny kituo chetu cha YouTube.",
    },
    "tr": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/tr_m.flac",
        "text": "Ge√ßen ay YouTube kanalƒ±mƒ±zda iki milyar g√∂r√ºnt√ºleme ile yeni bir d√∂n√ºm noktasƒ±na ula≈ütƒ±k.",
    },
    "zh": {
        "audio": "https://storage.googleapis.com/chatterbox-demo-samples/mtl_prompts/zh_f2.flac",
        "text": "‰∏ä‰∏™ÊúàÔºåÊàë‰ª¨ËææÂà∞‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÈáåÁ®ãÁ¢ë„ÄÇ Êàë‰ª¨ÁöÑYouTubeÈ¢ëÈÅìËßÇÁúãÊ¨°Êï∞ËææÂà∞‰∫Ü‰∫åÂçÅ‰∫øÊ¨°ÔºåËøôÁªùÂØπ‰ª§‰∫∫Èöæ‰ª•ÁΩÆ‰ø°„ÄÇ",
    },
}


# --- UI Helpers ---
def default_audio_for_ui(lang: str) -> str | None:
    return LANGUAGE_CONFIG.get(lang, {}).get("audio")


def default_text_for_ui(lang: str) -> str:
    return LANGUAGE_CONFIG.get(lang, {}).get("text", "")


def get_supported_languages_display() -> str:
    """Generate a formatted display of all supported languages."""
    language_items = []
    for code, name in sorted(SUPPORTED_LANGUAGES.items()):
        language_items.append(f"**{name}** (`{code}`)")

    # Split into 2 lines
    mid = len(language_items) // 2
    line1 = " ‚Ä¢ ".join(language_items[:mid])
    line2 = " ‚Ä¢ ".join(language_items[mid:])

    return f"""
### üåç Supported Languages ({len(SUPPORTED_LANGUAGES)} total)
{line1}

{line2}
"""


def get_or_load_model():
    """Loads the ChatterboxMultilingualTTS model if it hasn't been loaded already,
    and ensures it's on the correct device."""
    global MODEL, ENHANCED_TTS
    if MODEL is None:
        print("Model not loaded, initializing...")
        try:
            # Convert string device to torch.device object
            device_obj = torch.device(DEVICE)
            MODEL = ChatterboxMultilingualTTS.from_pretrained(device_obj)
            if hasattr(MODEL, "to") and str(MODEL.device) != DEVICE:
                MODEL.to(device_obj)

            # Initialize enhanced TTS with chunking support
            if ENHANCED_TTS is None:
                ENHANCED_TTS = create_enhanced_tts(
                    model=MODEL,
                    device=DEVICE,
                    logger=None,  # Use default logger
                )
                print("Enhanced TTS with text chunking initialized")

            print(
                f"Model loaded successfully. Internal device: {getattr(MODEL, 'device', 'N/A')}"
            )
        except Exception as e:
            print(f"Error loading model: {e}")
            raise
    return MODEL


# Attempt to load the model at startup.
try:
    get_or_load_model()
except Exception as e:
    print(
        f"CRITICAL: Failed to load model on startup. Application may not function. Error: {e}"
    )


def set_seed(seed: int):
    """Sets the random seed for reproducibility across torch, numpy, and random."""
    torch.manual_seed(seed)
    if DEVICE == "cuda":
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    elif DEVICE == "mps":
        # MPS (Metal Performance Shaders) doesn't require specific seeding
        # but we keep the structure for consistency
        pass
    random.seed(seed)
    np.random.seed(seed)


def resolve_audio_prompt(language_id: str, provided_path: str | None) -> str | None:
    """
    Decide which audio prompt to use:
    - If user provided a path (upload/mic/url), use it.
    - Else, fall back to language-specific default (if any).
    """
    if provided_path and str(provided_path).strip():
        return provided_path
    return LANGUAGE_CONFIG.get(language_id, {}).get("audio")


def generate_tts_audio(
    text_input: str,
    language_id: str,
    audio_prompt_path_input: str = None,
    exaggeration_input: float = 0.5,
    temperature_input: float = 0.8,
    seed_num_input: int = 0,
    cfgw_input: float = 0.5,
) -> tuple[int, np.ndarray]:
    """
    Generate high-quality speech audio from text using enhanced Chatterbox Multilingual model with intelligent text chunking.
    Supports long texts by automatically splitting them at natural break points and concatenating the generated audio.

    This enhanced version uses smart text chunking to handle texts longer than 300 characters while maintaining
    natural speech flow. Each chunk is generated separately and then seamlessly concatenated together.

    Args:
        text_input (str): The text to synthesize into speech (supports unlimited length with automatic chunking)
        language_id (str): The language code for synthesis (supports all 23 languages)
        audio_prompt_path_input (str, optional): File path or URL to the reference audio file that defines the target voice style. Defaults to None.
        exaggeration_input (float, optional): Controls speech expressiveness (0.25-2.0, neutral=0.5, extreme values may be unstable). Defaults to 0.5.
        temperature_input (float, optional): Controls randomness in generation (0.05-5.0, higher=more varied). Defaults to 0.8.
        seed_num_input (int, optional): Random seed for reproducible results (0 for random generation). Defaults to 0.
        cfgw_input (float, optional): CFG/Pace weight controlling generation guidance (0.2-1.0). Defaults to 0.5, 0 for language transfer.

    Returns:
        tuple[int, np.ndarray]: A tuple containing the sample rate (int) and the generated audio waveform (numpy.ndarray)
    """
    global ENHANCED_TTS

    # Load model and initialize enhanced TTS if needed
    if ENHANCED_TTS is None:
        current_model = get_or_load_model()
        if current_model is None:
            raise RuntimeError("TTS model failed to load.")

    if ENHANCED_TTS is None:
        raise RuntimeError("Enhanced TTS system failed to initialize.")

    if seed_num_input != 0:
        set_seed(int(seed_num_input))

    print(
        f"üöÄ Generating audio with enhanced TTS for text: '{text_input[:50]}{'...' if len(text_input) > 50 else ''}' (length: {len(text_input)} chars)"
    )

    # Create generation configuration for enhanced TTS
    config = TTSGenerationConfig(
        max_chars=300,  # Chunk size
        language_id=language_id,
        exaggeration=exaggeration_input,
        temperature=temperature_input,
        cfg_weight=cfgw_input,
        show_progress=True,
        enable_tqdm=True,
        concatenate_audio=True,
        add_silence_between_chunks=0.05,  # 50ms silence between chunks
    )

    try:
        # Use enhanced TTS for generation with automatic chunking
        result = ENHANCED_TTS.generate(text_input, config)

        print(
            f"‚úÖ Audio generation complete! Generated {result.chunk_count} chunks, duration: {result.duration:.2f}s"
        )

        # Return in the expected format (sample_rate, audio_data)
        return (result.sample_rate, result.audio_data.squeeze(0))

    except Exception as e:
        print(f"‚ùå Enhanced TTS generation failed: {str(e)}")
        print("üîÑ Falling back to basic model generation...")

        # Fallback to original model for compatibility
        current_model = get_or_load_model()
        if current_model is None:
            raise RuntimeError("TTS model is not loaded.")

        # Handle optional audio prompt for fallback
        chosen_prompt = audio_prompt_path_input or default_audio_for_ui(language_id)

        generate_kwargs = {
            "exaggeration": exaggeration_input,
            "temperature": temperature_input,
            "cfg_weight": cfgw_input,
        }
        if chosen_prompt:
            generate_kwargs["audio_prompt_path"] = chosen_prompt
            print(f"Using audio prompt: {chosen_prompt}")
        else:
            print("No audio prompt provided; using default voice.")

        # Truncate text to 300 chars for fallback
        fallback_text = text_input[:300]
        if len(text_input) > 300:
            print(f"‚ö†Ô∏è Text truncated to 300 characters for fallback generation")

        wav = current_model.generate(
            fallback_text,
            language_id=language_id,
            **generate_kwargs,
        )
        print("Fallback audio generation complete.")
        return (current_model.sr, wav.squeeze(0).numpy())


with gr.Blocks() as demo:
    gr.Markdown(
        """
        # Chatterbox Multilingual Demo
        Generate high-quality multilingual speech from text with reference audio styling, supporting 23 languages.

        For a hosted version of Chatterbox Multilingual and for finetuning, please visit [resemble.ai](https://app.resemble.ai)
        """
    )

    # Display supported languages
    gr.Markdown(get_supported_languages_display())
    with gr.Row():
        with gr.Column():
            initial_lang = "fr"
            text = gr.Textbox(
                value=default_text_for_ui(initial_lang),
                label="Text to synthesize (unlimited length with automatic chunking)",
                max_lines=5,
            )

            language_id = gr.Dropdown(
                choices=list(
                    ChatterboxMultilingualTTS.get_supported_languages().keys()
                ),
                value=initial_lang,
                label="Language",
                info="Select the language for text-to-speech synthesis",
            )

            ref_wav = gr.Audio(
                sources=["upload", "microphone"],
                type="filepath",
                label="Reference Audio File (Optional)",
                value=default_audio_for_ui(initial_lang),
            )

            gr.Markdown(
                "üí° **Note**: Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clip's language. To mitigate this, set the CFG weight to 0.",
                elem_classes=["audio-note"],
            )

            exaggeration = gr.Slider(
                0.25,
                2,
                step=0.05,
                label="Exaggeration (Neutral = 0.5, extreme values can be unstable)",
                value=0.5,
            )
            cfg_weight = gr.Slider(0.2, 1, step=0.05, label="CFG/Pace", value=0.5)

            with gr.Accordion("More options", open=False):
                seed_num = gr.Number(value=0, label="Random seed (0 for random)")
                temp = gr.Slider(0.05, 5, step=0.05, label="Temperature", value=0.8)

            run_btn = gr.Button("Generate", variant="primary")

        with gr.Column():
            audio_output = gr.Audio(label="Output Audio")

        def on_language_change(lang, current_ref, current_text):
            return default_audio_for_ui(lang), default_text_for_ui(lang)

        language_id.change(
            fn=on_language_change,
            inputs=[language_id, ref_wav, text],
            outputs=[ref_wav, text],
            show_progress=False,
        )

    run_btn.click(
        fn=generate_tts_audio,
        inputs=[
            text,
            language_id,
            ref_wav,
            exaggeration,
            temp,
            seed_num,
            cfg_weight,
        ],
        outputs=[audio_output],
    )

demo.launch()
